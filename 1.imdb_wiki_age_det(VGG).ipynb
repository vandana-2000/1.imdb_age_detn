{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGE DETECTION ON IMDB-WIKI DATASET "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='IMDB-Wiki'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (224, 224, 3), Age: 37.0\n",
      "Image shape: (224, 224, 3), Age: 33.0\n",
      "Image shape: (224, 224, 3), Age: 28.0\n",
      "Image shape: (224, 224, 3), Age: 46.0\n",
      "Image shape: (224, 224, 3), Age: 44.0\n",
      "WARNING:tensorflow:From C:\\Users\\SARATHLAL\\AppData\\Local\\Temp\\ipykernel_1328\\3422552786.py:48: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "def calculate_age_from_filename(filename):\n",
    "    try:        \n",
    "        parts = filename.split('_')\n",
    "        birthdate_str = parts[2]  \n",
    "        photo_year = int(parts[3].split('.')[0]) \n",
    "        \n",
    "        birthdate_parts = birthdate_str.split('-')\n",
    "        birth_year = int(birthdate_parts[0])\n",
    "        birth_month = int(birthdate_parts[1]) if birthdate_parts[1] != '0' else 1\n",
    "        birth_day = int(birthdate_parts[2]) if birthdate_parts[2] != '0' else 1\n",
    "\n",
    "        age = photo_year - birth_year\n",
    "        return age\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    ages = []\n",
    "\n",
    "    for dir_name, _, filenames in os.walk(data_dir):\n",
    "        for filename in filenames:\n",
    "            img_path = os.path.join(dir_name, filename)\n",
    "            age = calculate_age_from_filename(filename)\n",
    "            if age is not None:\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img.verify() \n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    img = img.resize((224, 224))  \n",
    "                    img = np.array(img) / 255.0  \n",
    "                    images.append(img)\n",
    "                    ages.append(age)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    return np.array(images, dtype='float32'), np.array(ages, dtype='float32')\n",
    "\n",
    "images, ages = load_data(data_dir)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, ages))\n",
    "\n",
    "for image, age in dataset.take(5):\n",
    "    print(f\"Image shape: {image.shape}, Age: {age.numpy()}\")\n",
    "\n",
    "tf.data.experimental.save(dataset, 'age_detection_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(images, ages, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1)(x)  \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 6s/step - loss: 373.0916 - mae: 14.6384 - val_loss: 192.5018 - val_mae: 9.8997\n",
      "Epoch 2/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 6s/step - loss: 219.8428 - mae: 11.4036 - val_loss: 296.1147 - val_mae: 12.9689\n",
      "Epoch 3/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 6s/step - loss: 231.8870 - mae: 11.6003 - val_loss: 242.0675 - val_mae: 11.4974\n",
      "Epoch 4/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 6s/step - loss: 170.3378 - mae: 9.9981 - val_loss: 268.8062 - val_mae: 12.4156\n",
      "Epoch 5/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 6s/step - loss: 167.7003 - mae: 10.0691 - val_loss: 192.3312 - val_mae: 10.0768\n",
      "Epoch 6/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 6s/step - loss: 159.8135 - mae: 9.6937 - val_loss: 220.0211 - val_mae: 10.8979\n",
      "Epoch 7/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 6s/step - loss: 145.1538 - mae: 9.3074 - val_loss: 270.7570 - val_mae: 12.5738\n",
      "Epoch 8/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 6s/step - loss: 146.7985 - mae: 9.3479 - val_loss: 540.9284 - val_mae: 19.9320\n",
      "Epoch 9/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 6s/step - loss: 170.5311 - mae: 10.0643 - val_loss: 288.5758 - val_mae: 13.1986\n",
      "Epoch 10/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 5s/step - loss: 119.6890 - mae: 8.3786 - val_loss: 288.3173 - val_mae: 13.1439\n",
      "Epoch 11/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 6s/step - loss: 120.3600 - mae: 8.4031 - val_loss: 337.9103 - val_mae: 14.6159\n",
      "Epoch 12/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 6s/step - loss: 110.3625 - mae: 8.0988 - val_loss: 200.7921 - val_mae: 10.3123\n",
      "Epoch 13/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 6s/step - loss: 116.7422 - mae: 8.4269 - val_loss: 343.8880 - val_mae: 14.9237\n",
      "Epoch 14/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 6s/step - loss: 97.2553 - mae: 7.5420 - val_loss: 307.8506 - val_mae: 13.7583\n",
      "Epoch 15/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 6s/step - loss: 103.5607 - mae: 7.8981 - val_loss: 308.3676 - val_mae: 13.8705\n",
      "Epoch 16/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 6s/step - loss: 109.1988 - mae: 8.1778 - val_loss: 277.8376 - val_mae: 12.9590\n",
      "Epoch 17/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 6s/step - loss: 93.6948 - mae: 7.4536 - val_loss: 352.6201 - val_mae: 15.1310\n",
      "Epoch 18/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 6s/step - loss: 88.2006 - mae: 7.3482 - val_loss: 311.7647 - val_mae: 13.9362\n",
      "Epoch 19/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 6s/step - loss: 82.9775 - mae: 6.9757 - val_loss: 341.1120 - val_mae: 14.7596\n",
      "Epoch 20/20\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 6s/step - loss: 86.6439 - mae: 7.2642 - val_loss: 259.4347 - val_mae: 12.4446\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('age_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 4s/step - loss: 269.2838 - mae: 12.7688\n",
      "Test MAE: 12.444560050964355\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(x_val, y_val)\n",
    "print(f'Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('age_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict age\n",
    "def predict_age(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((224, 224))  \n",
    "        img_array = np.array(img) / 255.0  \n",
    "        img_array = np.expand_dims(img_array, axis=0)  \n",
    "\n",
    "        # Predict age\n",
    "        predicted_age = model.predict(img_array)\n",
    "        return int(predicted_age[0][0])\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error in predicting age: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open image file\n",
    "def open_file():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select Image\",\n",
    "        filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        load_image(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and display image\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.thumbnail((300, 300))  \n",
    "        \n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        panel.configure(image=img_tk)\n",
    "        panel.image = img_tk  \n",
    "\n",
    "        # Predict age\n",
    "        predicted_age = predict_age(image_path)\n",
    "        if predicted_age is not None:\n",
    "            age_label.config(text=f\"Predicted Age: {predicted_age}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error loading image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Age Detection\")\n",
    "\n",
    "panel = tk.Label(root)\n",
    "panel.pack(padx=10, pady=10)\n",
    "\n",
    "age_label = tk.Label(root, text=\"Predicted Age: \", font=(\"Helvetica\", 14))\n",
    "age_label.pack(pady=20)\n",
    "\n",
    "open_button = tk.Button(root, text=\"Upload Image\", command=open_file)\n",
    "open_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
